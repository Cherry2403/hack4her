defaults:
  - finetune: rl_llama31_8b
  - _self_

n_workers: 32
max_loops: 10
test_every_n_iterations: 5
model_path: /mnt/llmd/base_models/Meta-Llama-3.1-8B-Instruct
# model_path: meta-llama/Meta-Llama-3.1-8B-Instruct
max_agent_forks: 1024
attempts: 64
length_penalty: 0.0
normalize_reward_per_step: true
force_restart: false
max_iterations: 100
llm:
  parameters:
    max_tokens: 1024
    temperature: 0.7
test_llm:
  parameters:
    max_tokens: 1024
    temperature: 0.

finetune:
  config_name: ${..model_path}
  output_dir: ${..output_dir}/finetune

vllm_config:
  vllm_kwargs:
    - "--download-dir": "/mnt/llmd/base_models/" 
    - "--gpu-memory-utilization": 0.8   
    - "--max-model-len": 8000

output_dir: outputs/rl_gsm8k_v3

hydra:
  job_logging:
    root:
      level: DEBUG