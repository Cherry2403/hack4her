defaults:
  - _self_
  - agent: gaia_fcalls

exp_name: mcp_test_qwen_toolcalls_1
exp_path: outputs/gaia/runs/${exp_name}

llm:
  _target_: tapeagents.llms.TrainableLLM
  base_url: "http://localhost:8000"
  model_name: Qwen/Qwen3-8B
  use_litellm_tokenizer_fallback: true
  use_cache: false
  context_size: 128000
  parameters:
    temperature: 0.7
    top_p: 0.8 # from https://huggingface.co/Qwen/Qwen3-8B for non-thinking mode. For thinking mode use t=0.6 p=0.95
    top_k: 20
    chat_template_kwargs:
      enable_thinking: false

environment:
  _target_: tapeagents.mcp.MCPEnvironment
  config_path: conf/mcp/web_and_code.json

split: validation
only_tasks: #[] # list of (level, task_num)
- [1, 0]
- [1, 1]
- [1, 2]
- [1, 3]
- [1, 4]
- [1, 5]
- [1, 6]
- [1, 7]

hydra:
  run:
    dir: ${exp_path}