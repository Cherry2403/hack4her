defaults:
  - _self_
  - agent: gaia_fcalls

exp_name: mcp_test_qwen_sync
exp_path: outputs/gaia/runs/${exp_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}

llm:
  _target_: tapeagents.llms.TrainableLLM
  base_url: "http://localhost:8000"
  model_name: Qwen/Qwen3-8B
  use_litellm_tokenizer_fallback: true
  use_cache: false
  context_size: 32000
  parameters:
    temperature: 0.7
    top_p: 0.8 # from https://huggingface.co/Qwen/Qwen3-8B for non-thinking mode. For thinking mode use t=0.6 p=0.95
    top_k: 20
    chat_template_kwargs:
      enable_thinking: false

environment:
  _target_: tapeagents.remote_environment.AsyncRemoteEnvironment
  server_url: http://localhost:8000

split: validation
only_tasks: #[] # list of (level, task_num)
- [1, 0]
- [1, 1]
# - [1, 2]
# - [1, 3]
# - [1, 4]
# - [1, 5]
# - [1, 6]
# - [1, 7]
# - [1, 8]
# - [1, 9]
# - [1, 10]
# - [1, 11]
# - [1, 12]
# - [1, 13]
# - [1, 14]
# - [1, 15]
# - [1, 16]
# - [1, 17]
# - [1, 18]
# - [1, 19]
# - [1, 20]
# - [1, 21]
# - [1, 22]
# - [1, 23]
# - [1, 24]
# - [1, 25]
# - [1, 26]
# - [1, 27]
# - [1, 28]
# - [1, 29]
# - [1, 30]
# - [1, 31]

hydra:
  run:
    dir: ${exp_path}